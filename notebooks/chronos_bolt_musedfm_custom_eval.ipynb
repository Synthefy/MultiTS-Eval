{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Quick Start: Running Chronos Bolt on MUSED-FM Benchmark\n",
        "\n",
        "This notebook shows how to run Chronos Bolt models on the MUSED-FM benchmark using the `run_musedfm.py` script.\n",
        "\n",
        "Make sure you have the MUSED-FM benchmark data downloaded and set the `--benchmark-path` correctly before running this notebook.\n",
        "\n",
        "We will use the MUSED-FM framework to load the data and run the Chronos Bolt model. This notebook demonstrates how to integrate Chronos Bolt with the MUSED-FM evaluation framework.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Installation\n",
        "\n",
        "Install required packages:\n",
        "\n",
        "```bash\n",
        "pip install chronos-forecasting\n",
        "pip install musedfm\n",
        "```\n",
        "\n",
        "Make sure you have PyTorch installed with CUDA support if you want to use GPU acceleration.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MUSED-FM components imported successfully!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from pathlib import Path\n",
        "from typing import Optional\n",
        "from abc import ABC, abstractmethod\n",
        "\n",
        "# Add the src directory to the Python path\n",
        "sys.path.insert(0, str(Path.cwd() / 'src'))\n",
        "\n",
        "# Import MUSED-FM components\n",
        "from musedfm.data import Benchmark\n",
        "from musedfm.metrics import MAPE, MAE, RMSE, NMAE\n",
        "\n",
        "print(\"MUSED-FM components imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ChronosForecast class defined successfully!\n"
          ]
        }
      ],
      "source": [
        "# Self-contained ChronosForecast class for the notebook\n",
        "class ChronosForecast:\n",
        "    \"\"\"\n",
        "    Chronos forecasting model wrapper for MUSED-FM evaluation.\n",
        "    This class is self-contained within the notebook.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, model_path: str = \"amazon/chronos-bolt-base\", device: str = \"cuda:0\", num_samples: int = 20):\n",
        "        \"\"\"\n",
        "        Initialize Chronos forecast model.\n",
        "        \n",
        "        Args:\n",
        "            model_path: Path to Chronos model (HuggingFace model ID or local path)\n",
        "            device: Device to run the model on\n",
        "            num_samples: Number of samples for probabilistic forecasting\n",
        "        \"\"\"\n",
        "        self.model_path = model_path\n",
        "        self.device = device\n",
        "        self.num_samples = num_samples\n",
        "        self.pipeline = None\n",
        "        self._load_model()\n",
        "    \n",
        "    def _load_model(self):\n",
        "        \"\"\"Load the Chronos model.\"\"\"\n",
        "        try:\n",
        "            from chronos import BaseChronosPipeline, ForecastType\n",
        "            \n",
        "            self.pipeline = BaseChronosPipeline.from_pretrained(\n",
        "                self.model_path,\n",
        "                device_map=self.device,\n",
        "            )\n",
        "            print(f\"Loaded Chronos model: {self.model_path}\")\n",
        "        except ImportError:\n",
        "            raise ImportError(\"Chronos package not installed. Please install with: pip install chronos-forecasting\")\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"Failed to load Chronos model: {e}\")\n",
        "    \n",
        "    def forecast(self, history: np.ndarray, covariates: Optional[np.ndarray] = None, forecast_horizon: Optional[int] = None) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Generate forecast from historical data using Chronos.\n",
        "        \n",
        "        Args:\n",
        "            history: Historical time series data\n",
        "            covariates: Optional covariate data (ignored for Chronos)\n",
        "            forecast_horizon: Number of future points to forecast (default: 1)\n",
        "            \n",
        "        Returns:\n",
        "            Forecast values\n",
        "        \"\"\"\n",
        "        if forecast_horizon is None:\n",
        "            forecast_horizon = 1\n",
        "        \n",
        "        # Convert history to torch tensor\n",
        "        if isinstance(history, np.ndarray):\n",
        "            history_tensor = torch.tensor(history, dtype=torch.float32)\n",
        "        else:\n",
        "            history_tensor = torch.tensor(np.array(history), dtype=torch.float32)\n",
        "        \n",
        "        # Remove NaN values\n",
        "        history_clean = history_tensor[~torch.isnan(history_tensor)]\n",
        "        \n",
        "        if len(history_clean) == 0:\n",
        "            # If no valid data, return zeros\n",
        "            return np.zeros(forecast_horizon)\n",
        "        \n",
        "        # Ensure we have enough history for forecasting\n",
        "        if len(history_clean) < 2:\n",
        "            # If insufficient data, return the last value repeated\n",
        "            last_value = float(history_clean[-1]) if len(history_clean) > 0 else 0.0\n",
        "            return np.full(forecast_horizon, last_value)\n",
        "        \n",
        "        # Generate forecast using Chronos\n",
        "        context = [history_clean]\n",
        "        \n",
        "        # Determine prediction kwargs based on forecast type\n",
        "        predict_kwargs = {}\n",
        "        if hasattr(self.pipeline, 'forecast_type'):\n",
        "            from chronos import ForecastType\n",
        "            if self.pipeline.forecast_type == ForecastType.SAMPLES:\n",
        "                predict_kwargs = {\"num_samples\": self.num_samples}\n",
        "        \n",
        "        # Generate forecast\n",
        "        forecast_output = self.pipeline.predict(\n",
        "            context,\n",
        "            prediction_length=forecast_horizon,\n",
        "            **predict_kwargs\n",
        "        )\n",
        "        \n",
        "        # Convert to numpy array\n",
        "        if isinstance(forecast_output, torch.Tensor):\n",
        "            forecast_np = forecast_output.numpy()\n",
        "        else:\n",
        "            forecast_np = np.array(forecast_output)\n",
        "        \n",
        "        # Handle different output shapes\n",
        "        if forecast_np.ndim > 1:\n",
        "            # Chronos Bolt returns (batch_size, num_quantiles, prediction_length)\n",
        "            # We want the median (0.5 quantile) which is typically at index 4 (0.1, 0.2, ..., 0.9)\n",
        "            if forecast_np.ndim == 3 and forecast_np.shape[1] == 9:  # Standard Chronos Bolt quantiles\n",
        "                # Take the median (0.5 quantile) at index 4\n",
        "                forecast_np = forecast_np[0, 4, :]  # (batch_size=1, quantile=4, prediction_length)\n",
        "            elif forecast_np.shape[0] > 1:\n",
        "                # If we have multiple samples, take the mean\n",
        "                forecast_np = np.mean(forecast_np, axis=0)\n",
        "            else:\n",
        "                forecast_np = forecast_np[0]\n",
        "        \n",
        "        # Ensure we have the right length\n",
        "        if len(forecast_np) != forecast_horizon:\n",
        "            if len(forecast_np) > forecast_horizon:\n",
        "                forecast_np = forecast_np[:forecast_horizon]\n",
        "            else:\n",
        "                # Pad with the last value if needed - use concatenation to avoid broadcasting issues\n",
        "                if len(forecast_np) > 0:\n",
        "                    last_val = float(forecast_np[-1])\n",
        "                    padding_length = forecast_horizon - len(forecast_np)\n",
        "                    padding = np.full(padding_length, last_val)\n",
        "                    forecast_np = np.concatenate([forecast_np, padding])\n",
        "                else:\n",
        "                    # If no valid forecast, fill with zeros\n",
        "                    forecast_np = np.zeros(forecast_horizon)\n",
        "        \n",
        "        return forecast_np\n",
        "\n",
        "print(\"ChronosForecast class defined successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration\n",
        "\n",
        "Set up the benchmark path and model parameters. Adjust these according to your setup.\n",
        "ma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Benchmark path: /workspace/data/fm_eval_nested/\n",
            "Model: amazon/chronos-bolt-base\n",
            "Device: cuda:0\n",
            "Output directory: ./results/chronos_bolt\n"
          ]
        }
      ],
      "source": [
        "# Configuration\n",
        "BENCHMARK_PATH = \"/dev/shm/data/mused-fm-nested/\"  # Adjust this path to your MUSED-FM data\n",
        "MODEL_PATH = \"amazon/chronos-bolt-base\"  # Chronos Bolt model\n",
        "DEVICE = \"cuda:0\"  # Use \"cpu\" if you don't have CUDA\n",
        "NUM_SAMPLES = 20  # Number of samples for probabilistic forecasting\n",
        "MAX_WINDOWS = 50  # Limit windows per dataset for faster testing\n",
        "OUTPUT_DIR = \"./run/user/1013/musedfm_runs/chronos_bolt\"\n",
        "HISTORY_LENGTH = 512\n",
        "FORECAST_HORIZON = 128\n",
        "STRIDE = 256\n",
        "\n",
        "# Create output directory\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"Benchmark path: {BENCHMARK_PATH}\")\n",
        "print(f\"Model: {MODEL_PATH}\")\n",
        "print(f\"Device: {DEVICE}\")\n",
        "print(f\"Output directory: {OUTPUT_DIR}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initialize Chronos Model\n",
        "\n",
        "Create a ChronosForecast instance that integrates with the MUSED-FM framework.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded Chronos model: amazon/chronos-bolt-base\n",
            "Chronos model initialized successfully!\n"
          ]
        }
      ],
      "source": [
        "# Initialize Chronos model\n",
        "try:\n",
        "    chronos_model = ChronosForecast(\n",
        "        model_path=MODEL_PATH,\n",
        "        device=DEVICE,\n",
        "        num_samples=NUM_SAMPLES,        \n",
        "    )\n",
        "    print(\"Chronos model initialized successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"Error initializing Chronos model: {e}\")\n",
        "    print(\"Make sure you have installed chronos-forecasting and have the required dependencies.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run Chronos Model Directly in Notebook\n",
        "\n",
        "Instead of using `run_musedfm.py`, we can run Chronos directly in the notebook for more control and immediate results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading MUSED-FM benchmark...\n",
            "Loading KITTI data from /workspace/data/fm_eval_nested/sequential/KITTI\n",
            "Found 6114 parquet files\n",
            "Successfully loaded 6114 valid files\n",
            "Domain ALL_DATASETS not found in file hierarchy\n",
            "successfully counted windows from cached JSON files\n",
            "Domain ALL_DATASETS not found in file hierarchy\n",
            "successfully counted windows from cached JSON files\n",
            "Dataset aus_electricity not found in data_hierarchy.json\n",
            "Loading ECL data from /workspace/data/fm_eval_nested/traditional/ecl\n",
            "Found 1 parquet files\n",
            "Successfully loaded 1 valid files\n",
            "/workspace/data/fm_eval_nested/traditional/open_aq [PosixPath('/workspace/data/fm_eval_nested/traditional/open_aq/delhi_combined.parquet'), PosixPath('/workspace/data/fm_eval_nested/traditional/open_aq/reykjavik_combined.parquet'), PosixPath('/workspace/data/fm_eval_nested/traditional/open_aq/rotterdam_combined.parquet'), PosixPath('/workspace/data/fm_eval_nested/traditional/open_aq/winnipeg_combined.parquet')]\n",
            "Domain ALL_DATASETS not found in file hierarchy\n",
            "successfully counted windows from cached JSON files\n",
            "Domain ALL_DATASETS not found in file hierarchy\n",
            "successfully counted windows from cached JSON files\n",
            "Benchmark loaded successfully!\n",
            "Number of categories: 4\n",
            "Category: sequential (4 domains)\n",
            "  Domain: Image (1 datasets)\n",
            "  Domain: Video (1 datasets)\n",
            "  Domain: Scientific (5 datasets)\n",
            "  Domain: Text (1 datasets)\n",
            "Category: synthetic (2 domains)\n",
            "  Domain: Causal Model (5 datasets)\n",
            "  Domain: Dynamic (1 datasets)\n",
            "Category: traditional (8 domains)\n",
            "  Domain: Energy (34 datasets)\n",
            "  Domain: Sales (6 datasets)\n",
            "  Domain: Environment (7 datasets)\n",
            "  Domain: Public Info (10 datasets)\n",
            "  Domain: Engineering (2 datasets)\n",
            "  Domain: Finance (8 datasets)\n",
            "  Domain: Health (2 datasets)\n",
            "  Domain: Web (1 datasets)\n",
            "Category: collections (2 domains)\n",
            "  Domain: Stock (1 datasets)\n",
            "  Domain: Wikipedia (1 datasets)\n",
            "Total datasets in benchmark: 86\n"
          ]
        }
      ],
      "source": [
        "# Load the MUSED-FM benchmark\n",
        "print(\"Loading MUSED-FM benchmark...\")\n",
        "try:\n",
        "    benchmark = Benchmark(BENCHMARK_PATH, history_length=HISTORY_LENGTH, forecast_horizon=FORECAST_HORIZON, stride=STRIDE, load_cached_counts=True)\n",
        "    print(f\"Benchmark loaded successfully!\")\n",
        "    print(f\"Number of categories: {len(benchmark)}\")\n",
        "    \n",
        "    # Print some basic info about the benchmark\n",
        "    total_datasets = 0\n",
        "    for category in benchmark:\n",
        "        print(f\"Category: {category.category} ({len(category)} domains)\")\n",
        "        for domain in category:\n",
        "            print(f\"  Domain: {domain.domain_name} ({len(domain)} datasets)\")\n",
        "            total_datasets += len(domain)\n",
        "    \n",
        "    print(f\"Total datasets in benchmark: {total_datasets}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"Error loading benchmark: {e}\")\n",
        "    print(f\"Make sure the benchmark path '{BENCHMARK_PATH}' is correct and contains MUSED-FM data.\")\n",
        "    raise\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Direct Evaluation\n",
        "\n",
        "Now let's run Chronos directly on the benchmark data for immediate results and full control.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting Chronos evaluation...\n",
            "Starting direct evaluation on up to 3 datasets...\n",
            "\n",
            "Evaluating dataset: cifar100_timeseries_csvs (1/3)\n",
            "Category: sequential, Domain: Image\n",
            "Dataset size: 150000 windows\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/caleb/MUSED-FM/.venv/lib/python3.11/site-packages/chronos/chronos_bolt.py:525: UserWarning: We recommend keeping prediction length <= 64. The quality of longer predictions may degrade since the model is not optimized for it. \n",
            "  warnings.warn(msg)\n",
            "/home/caleb/MUSED-FM/.venv/lib/python3.11/site-packages/chronos/chronos_bolt.py:525: UserWarning: We recommend keeping prediction length <= 64. The quality of longer predictions may degrade since the model is not optimized for it. \n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed 5 windows\n",
            "Average MAPE: 442.9949\n",
            "Average MAE: 1.9559\n",
            "Average RMSE: 2.8351\n",
            "Average NMAE: 9.7522\n",
            "\n",
            "Evaluating dataset: KITTI (2/3)\n",
            "Category: sequential, Domain: Video\n",
            "Dataset size: 7092 windows\n",
            "Processed 5 windows\n",
            "Average MAPE: 403.4574\n",
            "Average MAE: 199.8369\n",
            "Average RMSE: 253.6362\n",
            "Average NMAE: 0.3618\n",
            "\n",
            "Evaluating dataset: ant_csv_out (3/3)\n",
            "Category: sequential, Domain: Scientific\n",
            "Dataset size: 26753 windows\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/caleb/MUSED-FM/.venv/lib/python3.11/site-packages/chronos/chronos_bolt.py:525: UserWarning: We recommend keeping prediction length <= 64. The quality of longer predictions may degrade since the model is not optimized for it. \n",
            "  warnings.warn(msg)\n",
            "/home/caleb/MUSED-FM/.venv/lib/python3.11/site-packages/chronos/chronos_bolt.py:525: UserWarning: We recommend keeping prediction length <= 64. The quality of longer predictions may degrade since the model is not optimized for it. \n",
            "  warnings.warn(msg)\n",
            "/home/caleb/MUSED-FM/.venv/lib/python3.11/site-packages/chronos/chronos_bolt.py:525: UserWarning: We recommend keeping prediction length <= 64. The quality of longer predictions may degrade since the model is not optimized for it. \n",
            "  warnings.warn(msg)\n",
            "/home/caleb/MUSED-FM/.venv/lib/python3.11/site-packages/chronos/chronos_bolt.py:525: UserWarning: We recommend keeping prediction length <= 64. The quality of longer predictions may degrade since the model is not optimized for it. \n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed 5 windows\n",
            "Average MAPE: 3369.2645\n",
            "Average MAE: 0.5359\n",
            "Average RMSE: 1.1747\n",
            "Average NMAE: 52.3027\n",
            "\n",
            "Direct evaluation completed on 3 datasets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/caleb/MUSED-FM/.venv/lib/python3.11/site-packages/chronos/chronos_bolt.py:525: UserWarning: We recommend keeping prediction length <= 64. The quality of longer predictions may degrade since the model is not optimized for it. \n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "# Direct evaluation function\n",
        "def evaluate_chronos_directly(benchmark, model, max_datasets=5, max_windows_per_dataset=10):\n",
        "    \"\"\"\n",
        "    Directly evaluate Chronos model on benchmark data.\n",
        "    \"\"\"\n",
        "    results = []\n",
        "    dataset_count = 0\n",
        "    \n",
        "    print(f\"Starting direct evaluation on up to {max_datasets} datasets...\")\n",
        "    \n",
        "    for category in benchmark:\n",
        "        if dataset_count >= max_datasets:\n",
        "            break\n",
        "            \n",
        "        for domain in category:\n",
        "            if dataset_count >= max_datasets:\n",
        "                break\n",
        "                \n",
        "            for dataset in domain:\n",
        "                if dataset_count >= max_datasets:\n",
        "                    break\n",
        "                    \n",
        "                print(f\"\\nEvaluating dataset: {dataset.dataset_name} ({dataset_count + 1}/{max_datasets})\")\n",
        "                print(f\"Category: {category.category}, Domain: {domain.domain_name}\")\n",
        "                print(f\"Dataset size: {len(dataset)} windows\")\n",
        "                \n",
        "                # Limit windows for faster evaluation\n",
        "                windows_processed = 0\n",
        "                dataset_metrics = {'MAPE': [], 'MAE': [], 'RMSE': [], 'NMAE': []}\n",
        "                \n",
        "                for window in dataset:\n",
        "                    if windows_processed >= max_windows_per_dataset:\n",
        "                        break\n",
        "                        \n",
        "                    # Get history and future data\n",
        "                    history = window.history()\n",
        "                    target = window.target()\n",
        "                    covariates = window.covariates()\n",
        "                    forecast_horizon = len(target)\n",
        "                    \n",
        "                    # Generate forecast\n",
        "                    forecast = model.forecast(\n",
        "                        history=history,\n",
        "                        forecast_horizon=forecast_horizon,\n",
        "                        covariates=covariates\n",
        "                    )\n",
        "                    \n",
        "                    # Calculate metrics\n",
        "                    mape = MAPE(target, forecast)\n",
        "                    mae = MAE(target, forecast)\n",
        "                    rmse = RMSE(target, forecast)\n",
        "                    nmae = NMAE(target, forecast)\n",
        "                    \n",
        "                    dataset_metrics['MAPE'].append(mape)\n",
        "                    dataset_metrics['MAE'].append(mae)\n",
        "                    dataset_metrics['RMSE'].append(rmse)\n",
        "                    dataset_metrics['NMAE'].append(nmae)\n",
        "                    \n",
        "                    windows_processed += 1\n",
        "                        \n",
        "                \n",
        "                # Calculate average metrics for this dataset\n",
        "                if windows_processed > 0:\n",
        "                    avg_metrics = {}\n",
        "                    for metric_name, values in dataset_metrics.items():\n",
        "                        if values:\n",
        "                            avg_metrics[metric_name] = np.mean(values)\n",
        "                        else:\n",
        "                            avg_metrics[metric_name] = np.nan\n",
        "                    \n",
        "                    result = {\n",
        "                        'dataset': dataset.dataset_name,\n",
        "                        'category': category.category,\n",
        "                        'domain': domain.domain_name,\n",
        "                        'windows_processed': windows_processed,\n",
        "                        **avg_metrics\n",
        "                    }\n",
        "                    results.append(result)\n",
        "                    \n",
        "                    print(f\"Processed {windows_processed} windows\")\n",
        "                    print(f\"Average MAPE: {avg_metrics['MAPE']:.4f}\")\n",
        "                    print(f\"Average MAE: {avg_metrics['MAE']:.4f}\")\n",
        "                    print(f\"Average RMSE: {avg_metrics['RMSE']:.4f}\")\n",
        "                    print(f\"Average NMAE: {avg_metrics['NMAE']:.4f}\")\n",
        "                \n",
        "                dataset_count += 1\n",
        "    \n",
        "    return results\n",
        "\n",
        "# Run direct evaluation\n",
        "print(\"Starting Chronos evaluation...\")\n",
        "direct_results = evaluate_chronos_directly(benchmark, chronos_model, max_datasets=3, max_windows_per_dataset=5)\n",
        "print(f\"\\nDirect evaluation completed on {len(direct_results)} datasets\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
